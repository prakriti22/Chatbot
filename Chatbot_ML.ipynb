{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keQvq4RlxMRq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data=pd.pandas read_fwf('chat.txt')\n",
        "# data"
      ],
      "metadata": {
        "id": "BMjv6joQxRQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('/content/chat.txt','r',errors='ignore')\n",
        "raw=f.read()"
      ],
      "metadata": {
        "id": "AwcMyXEq6J1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw=raw.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "sentence_tokens=nltk.sent_tokenize(raw)\n",
        "word_tokens=nltk.word_tokenize(raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq3VGTaP6c_8",
        "outputId": "fd8e032d-88cf-41b1-c057-08d6a05f1c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[2:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhR8GvNY63cs",
        "outputId": "2ec82b53-464c-4593-ab99-017eedb8af68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the reason given is: this article is using citations from 1970 and virtually all claims about conversational capabilities are at least ten years out of date (for example the turing test was arguably made obsolete years ago by transformer models).']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing"
      ],
      "metadata": {
        "id": "AZlgw7vu83Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer=nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "  ##stop words removal\n",
        "remove_punc_dict=dict((ord(punct),None) for punct in string.punctuation)\n",
        "def LemNormalise(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))\n",
        "\n"
      ],
      "metadata": {
        "id": "IEmFAnUJ7RPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining greet function"
      ],
      "metadata": {
        "id": "1mpQ8z1v86-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greet_inputs=(\"hello\",\"hey\",\"hi\",\"whatsup\",\"sup\",\"how are you\",\"what macha\")\n",
        "greet_response=(\"hi\",\"hello\",\"Hey There!\",\"There there!\")\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in greet_inputs:\n",
        "      return random.choice(greet_response)"
      ],
      "metadata": {
        "id": "19MqKLmp8MMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "xqIz8P6X8p-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  resp=''\n",
        "  TfidfVec=TfidfVectorizer(tokenizer=LemNormalise, stop_words='english')\n",
        "  tfidf=TfidfVec.fit_transform(sentence_tokens)\n",
        "  vals=cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat=vals.flatten()\n",
        "  reg_tfidf=flat[-2]\n",
        "  if((reg_tfidf)==0):\n",
        "    resp=resp+\"I am sorry. Unable to understand you!\"\n",
        "  else:\n",
        "    resp=resp+sentence_tokens[idx]\n",
        "    return resp"
      ],
      "metadata": {
        "id": "Gi9nAWeC9U6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "chatflow definition"
      ],
      "metadata": {
        "id": "LmAHOc-g__8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "print(\"Hello, I am bot, You can start typing after your greetings. For ending the conversation text bye\")\n",
        "while(flag==True):\n",
        "  user_response=input()\n",
        "  user_response=user_response.lower()\n",
        "  if(user_response!='bye'):\n",
        "    if(user_response == 'thank you' or user_response =='thanks'):\n",
        "      flag=False\n",
        "      print('Bot: You are most Welcome')\n",
        "    else:\n",
        "      if(greet(user_response)!=None):\n",
        "        print('Bot: '+ greet(user_response))\n",
        "      else:\n",
        "        sentence_tokens.append(user_response)\n",
        "        word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "        final_words=list(set(word_tokens))\n",
        "        print(response(user_response))\n",
        "        sentence_tokens.remove(user_response)\n",
        "\n",
        "  else:\n",
        "    flag=False\n",
        "    print('Bot: Goodbye! Have a nice day!')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nEKlnvRABcs",
        "outputId": "aa9f82c3-c1e3-4785-b4a3-6c4ee042cff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, I am bot, You can start typing after your greetings. For ending the conversation text bye\n",
            "hi\n",
            "Bot: There there!\n",
            "can you tell me about chatbot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can you tell me about chatbot\n",
            "yes\n",
            "None\n",
            "ok\n",
            "None\n",
            "why\n",
            "None\n",
            "can you tell me about turing test\n",
            "can you tell me about turing test\n",
            "bye\n",
            "Bot: Goodbye! Have a nice day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RiETqp38BTNg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}